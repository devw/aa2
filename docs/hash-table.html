<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="UTF-8" />
        <meta http-equiv="X-UA-Compatible" content="IE=edge" />
        <meta name="viewport" content="width=device-width, initial-scale=1.0" />
        <title>Hash Table</title>
        <link rel="stylesheet" href="./main.css" />
        <link rel="stylesheet" href="./collapse.css" />
        <script src="vendors/highlight.min.js"></script>
        <script src="vendors/highlight.ln.min.js"></script>
        <link rel="stylesheet" href="vendors/highlight.min.css" />
    </head>
    <body>
        <!-- https://junminlee3.medium.com/hash-tables-animations-that-will-make-you-understand-how-they-work-d1bcc850ba71 -->
        <!-- /Users/antonio/Downloads/Lecture17.pdf -->
        <h1><a href="./">Home</a></h1>
        <article id="introduction">
            <details>
                <summary>The Map Data Structure</summary>
                <h2>Why Hashing?</h2>
                <p>
                    Internet has grown to millions of users generating terabytes of content every day. According to internet data tracking services, the amount of content on the internet doubles every six months. With this kind of growth, it is impossible to find anything in the internet, unless we develop new data structures and algorithms for storing and accessing data. So what is wrong with traditional data structures like Arrays and Linked Lists? Suppose we have a very large data set stored in an array. The amount of time required to look up an element in the array is either O(log n) or O( n) based on whether the array is sorted or not. If the array is sorted then a technique such as binary search can be used to search the array. Otherwise, the array must be searched linearly. Either case may not be desirable if we need to process a very large data set. Therefore we discuss a new technique called hashing that allows us to update and retrieve any entry in constant time O(1). The constant time or O(1) performance means, the amount of time to perform the operation does not depend on data size n.
                </p>
                <h2>Definition</h2>
                <p>In a mathematical sense, a map is a relation between two sets. We can define Map M as a set of pairs, where each pair is of the form (key, value), where for given a key, we can find a value using some kind of a “function” that maps keys to values. The key for a given object can be calculated using a function called a hash function. In its simplest form, we can think of an array as a Map where key is the index and value is the value at that index. For example, given an array A, if i is the key, then we can find the value by simply looking up A[i]. The idea of a hash table is more generalized and can be described as follows.
                </p>
                <p>The concept of a hash table is a generalized idea of an array where key does not have to be an integer. We can have a name as a key, or for that matter any object as the key. The trick is to find a hash function to compute an index so that an object can be stored at a specific location in a table such that it can easily be found.</p>
                <var>hash: KEYS -> {0, 1, 2, ..., n - 1}</var>
                <img class="size-l" src="images/ht/brute-force.gif" alt="" />
                <h2>Example</h2>
                <p>Suppose we have a set of strings {“abc”, “def”, “ghi”} that we'd like to store in a table. Our objective here is to find or update them quickly from a table, actually in O(1). We are not concerned about ordering them or maintaining any order at all. Let us think of a simple schema to do this. Suppose we assign “a” = 1, “b”=2, ... etc to all alphabetical characters. We can then simply compute a number for each of the strings by using the sum of the characters as follows.</p>
                <var>“abc”=1+2+3=6, “def”=4+5+6=15 , “ghi”=7+8+9=24</var>
                <p>If we assume that we have a table of size 5 to store these strings, we can compute the
                    location of the string by taking the sum mod 5. So we will then store “abc” in 6 mod 5 = 1,“def” in 15 mod 5 = 0, and “ghi” in 24 mod 5 = 4 in locations 1, 0 and 4 as follows.</p>
                <pre><code class="python">
                    ["def", "abc", Null, Null, "ghi", Null]
                </code></pre>
                <h2>Hash Function Definition</h2>
                <p>
                    A hash function over a set 𝑋 is a function 𝐻 that takes an element 𝑥 in 𝑋 and associates to 𝑥 an
                    integer 𝐻 (𝑥 ) in the interval [0, 𝑀 ), for some integer 𝑀 . In symbols
                    <pre>
                        𝐻 ∶𝑋 → [0,𝑀)
                    </pre>
                </p>
                <img class="size-l" src="./images/ht/hash-function.gif" alt="" />
                <img class="size-l" src="./images/ht/hash-function-module.gif" alt="" />
                <h2>hash function</h2>
                <p>
                    There are three ways of calculating the hash function:
                    <ul>
                        <li>Division method</li>
                        <li>Folding method</li>
                        <li>Mid square method</li>
                    </ul>
                </p>
                <p>In the division method, the hash function can be defined as:</p>
<pre class="math">
h(ki) = ki mod m; 
//Modulo is a math operation that finds the remainder when one integer is divided by another. 
// In writing, it is frequently abbreviated as mod, or represented by the symbol %.
//  where m is the size of the hash table.
</pre>
                    
<p>
                    For example, if the key value is 6 and the size of the hash table is 10. When we apply the hash function to key 6 then the index would be:
                </p>             
                   <var> h(6) = 6 % 10 = 6</var>
                    <p>
                    The index is 6 at which the value is stored.</p>
                    <div>
                        <h4>Python Implementation</h4>
                        <pre><code class="python">
def hash_word(word, tablesize):
    return sum(ord(char) for char in word) % tablesize
                        </code></pre>
                    </div>
            </details>
        </article>
        <article>
            <details>
                <summary>Hash standard technique</summary>
                    <h2>Division hashing</h2>
                    <p>Division hashing method uses a modulo function on the key, by selecting a divisor M, the table size.</p>
                    <!-- <img class="w-500" src="./images/division.png" alt=""> -->
                    <pre ><code class="python">
def hash(word):
    sum = 0
    table_size = 10
    for char in word:
        sum += ord(char)
    return sum % table_size
                    </code></pre>
                    <!-- <h3>Exercise</h3>
                    <p>Write a python function to obtain the same result of the data shown in the table above </p>
                </div>-->
                <div>
                    <h2>Extracting (Extration)</h2>
                    <p>The extracting method extracts an appropriate number of bits and combines them to obtain a new decimal number.</p>
                    <img class="w-500" src="./images/extract-bits.png" alt="">
                    <p>By extracting n bits will have a hash function which output is an integer number ranging between 0 and 2^(n-1)</p>
                    <p>Let's suppose to extract bits 2, 7, 12 and 17.
                        The result is shown in the following figure.</p>
                    <img class="w-500" src="./images/extr-bits.png" alt="">
                    <p>Write a python function to obtain the result shown in the above image.</p>
                </div> 
                <div>
                    <h2>Folding (Compression)</h2>
                    <img class="w-500" src="./images/compression.png" alt="">
                    <p>Write a python function to obtain the result shown in the above image</p>
                    <pre class="blur"><code class="python">
def hash(word):
    res = 0
    for char in word:
        num = ord(char) - ord("A") + 1
        res = res ^ num
    return res

res = hash("CARO")
print(res)
                    </code></pre>
                </div>
                <div>
                    <h2>Multiplicative hashing</h2>
                    <p>
                        h(e) = [ (( x * &#x3D1; ) mod 1 ) * m]

                    </p>
                    <ul>
                        <li>e is the starting key (binary number/decimal number)</li>
                        <li>&#x3D1; is a real number (0 < &#x3D1; < 1)</li>
                        <li>m is the table size </li>
                        <li>the module is used to extract the decimal part.</li>
                    </ul>
                    <p>Here is the result by setting  &#x3D1; = 0.5987526325$ and  m = 27:</p>
                    <img class="w-500" src="./images/hash-mult.png" alt="">
                    <p>Write a python function to obtain the result shown in the above image</p>
                    <pre class="blur"><code class="python">
def hash(word):
    res = 0
    for char in word:
        num = ord(char) - ord("A") + 1
        res = res ^ num
    return res

res = hash("CARO")
print(res)
                    </code></pre>
                </div>
            </details>
        </article>
        <article id="hash-collision">
            <details>
                <summary>Problem with Hashing</summary>
                <h2>Introduction</h2>
                <p>

                    The hash function we used, that is the sum of the letters, is a bad one. In case we have permutations of the same letters, “abc”, “bac” etc in the set, we will end up with the same value for the sum and hence the key. In this case, the strings would hash into the same location, creating what we call a “collision”. This is obviously not a good thing. Secondly, we need to find a good table size, preferably a prime number so that even if the sums are different, then collisions can be avoided, when we take mod of the sum to find the location. So we ask two questions.
                </p>
                <ul>
                    <li>Question 1: How do we pick a good hash function?</li>
                    <li>Question 2: How do we deal with collisions?</li>
                </ul>
                <div>
                    <h2>Hash Collission</h2>
                    <p></p>
                    <img class="size-l" src="./images/ht/hash-function-collision.gif" alt="" />
                    <p>To handle hash collisions we can use two techniques: 1) closed addressing and 2) open addressing</p>
                </div>
            </details>
        </article>
        <article id="closed-addressing">
            <details>
                <summary>Open Hashing (Closed Addressing)</summary>
                <div>
                    <h2>Introduction</h2>
                    <p>Open hashing is also known as closed addressing</p>
                    <p>
                        The "open" in "open hashing" refers to the fact that we leave the hash table; we do not guarantee that the object is stored directly at an index in the hash table's internal array.
                    </p>
                    <p>
                        The "close" in "closed addressing" tells us the index (aka. address) at which an object will be stored in the hash table is completely determined by its hash code. Indeed, the object's index does not vary regardless of what's already in the hash table.
                    </p>
                </div>
                <div id="hashing-separate-chaining">
                    <h2>Chaining Method</h2>
                    <p>In open hashing, one of the methods used to resolve the collision is known as a chaining method.</p>
                    <img class="size-l" src="./images/separate-chaining.png" alt="">
                    <img class="size-l" src="./images/ht/hash.separate-chaining.gif" alt="" />
                    <p>
                        Suppose to place the values 12, 17, 29, 33, 42 and 39 with this hash function 
                    </p>
                    <var>h (x) = (x mod 10) + 1</var>
                    <p>We will obtain the following table (the new additions are made at the beginning of the list).</p>
                    <img src="./images/hash-collision-separate-chaining.png" alt="">
                    <p class="info">The NIL value indicated above represents an empty value, it is a constant often used in Algorithms. In python it is designated as None</p>
                </div>
                <div>
                    <p>Here is an example of the chaining method</p>
                    <img class="w-500" src="./images/chaining-method.png" alt="">
                </div>
            </details>
        </article>
        <article id="open-addressing">
            <details>
                <summary>Closed Hashing (Open Addressing)</summary>
                <div>
                    <h2>Introduction</h2>
                    <p>Closed Hashing is also known as open addressing</p>
                    <p>The open addressing is a technique for collision resolution.</p>
                    <p>The open addressing technique ensures that the data always remains within the same vector.</p>
                    <p>
                        It inserts the data into the hash table itself. The size of the hash table should be larger than
                        the number of keys.
                    </p>
                    <p>
                        The "open" in "open addressing" tells us the index (aka. address) at which an object will be stored in the hash table is not completely determined by its hash code. Instead, the index may vary depending on what's already in the hash table.
                    </p>
                    <p>
                        The "closed" in "closed hashing" refers to the fact that we never leave the hash table; every object is stored directly at an index in the hash table's internal array. Note that this is only possible by using some sort of open addressing strategy. This explains why "closed hashing" and "open addressing" are synonyms.
                    </p>
                </div>
                <div id="linear-probing">
                    <h2>Linear Probing</h2>
                    <img class="size-l" src="./images/ht/hash-open.addressing.gif" alt="" />
                    <p>Here is an example of the linear probing method.</p>
                    <img class="size-l" src="./images/linear.probing.png" alt="" />
                    <!-- TODO quadritic probing?-->
                </div>
                <div>
                    <h2>Quadratic Probing</h2>
                    <p>Quadratic probing can be a more efficient algorithm in an open addressing table, since it better avoids the clustering problem that can occur with linear probing.</p>
                    <div>
                        <h3>Implementation</h3>
                        <p>
                            Suppose 'h' is a hash function.
                            The different attempts are defined with the function try<sub>i</sub> 
                        </p>
                        <p>tri<sub>i</sub> = h(x) &oplus; c1 * (i - 1) &oplus; c2 * (i - 1)^2 </p>
                        <p>c1 = 1, c2 = 2</p>
                    </div>
                </div>
                <div id="re-hashing">
                    <h2>Re-Hashing (Double Hashing)</h2>
                    <img src="./images/overflow-area.gif" alt="">
                    <p>
                        Double Hashing works on a similar idea to linear probing. Whenever a collision occurs, choose another spot in table to put the value.
                        The difference here is that instead of choosing next free spot, a second hash function is used to determine the location of the next spot. For example, given hash function H1 and H2 and key. do the following:
                    </p>
                    <ul>
                        <li>Check location hash1(key). If it is empty, put record in it.</li>
                        <li>If it is not empty calculate hash2(key).</li>
                        <li>check if hash1(key)+hash2(key) is open, if it is, put it in.</li>
                        <li>repeat with hash1(key)+2hash2(key), hash1(key)+3hash2(key) and so on, until an opening is found.</li>
                    </ul>
                    <!-- TODO Double Hashing-->
                </div>
                <div>
                    <h3>Implementation</h3>
                    <p>
                        Suppose 'h' is a hash function.
                        The different attempts are defined with the function try<sub>i</sub> 
                    </p>
                    <p>try<sub>i</sub> = h(x) &oplus; d(x) * i </p>
                    <p>d(x) = h(x)  &oplus; 1</p>
                    <p>i &isin; {0, ..., m - 1}, (m the table size)</p>
                </div>

            </details>
            
        </article>
        <article>
            <details>
                <summary>Hybrid Solutions</summary>
                <div>
                    <h2>Coalesced Hashing</h2>
                    <!-- coalizzato, Hachage Coalescent -->
                    <p>The coalesced hashing method is a hybrid technique between the separate chaining method (open hashing) and an open addressing technique.</p>
                    <p>Example of separate chaining (open hashing and closed addressing).</p>
                    <img class="w-600" src="./images/separate-chaining-2.png" alt="">
                    <p>When a collision occurs, the new element is placed in the largest index available.</p>
                    <hr>
                    <p>Here is the first example of the coalesced hashing method.</p>
                    <img class="w-600" src="./images/coalesced-hashing.png" alt="">
                    <hr>
                    <p>Here is the second example of the coalesced hashing method. The memory is organized in two parts, the primary area and the reserve area. </p>
                    <img class="w-960" src="./images/coalesced-hashing-ex2.png" alt="">
                    <br>
                    <p>By adding the first four elements there are no collisions.</p>
                    <img class="w-300" src="./images/coalesced-hashing-step-1.png" alt="">
                    <p>The first collision (primary collision) occurs with the element x5.</p>
                    <img class="w-500" src="./images/coalesced-hashing-step-2.png" alt="">
                    <p>The x7 element is in collision with x1 which is in collision wiht x5.</p>
                    <img class="w-500" src="./images/coalesced-hashing-step-3.png" alt="">
                    <p>A secondary collision occurs with the x8 element. Indeed, the x5 element does not have the proper hash value to fill the 16th position.</p>
                    <img class="w-500" src="./images/coalesced-hashing-step-4.png" alt="">
                    <p>The final data structure will look like the below image.</p>
                    <img class="w-400" src="./images/coalesced-hashing-step-5.png" alt="">
                    <!-- https://www.youtube.com/watch?v=kj4Y5mFA2Qo -->
                    <p></p>
                </div>
            </details>
        </article>
        <article>
            <details>
                <summary>Conclusions on hashing methods</summary>
                <ul>
                    <li><b>Coalescing hashing</b> is the most efficient method if the memory area reserved for hashing must be fixed in advance (static data area).</li>
                    <li><b>Linear hashing</b> is the slowest, but this method has the advantage of being extremely simple to implement.</li>
                    <li><b>Double hashing</b> is more efficient than linear hashing, but it requires the calculation of two hash functions (and therefore their implementation).</li>
                    <li>Apart from separate chaining, hash methods do not support deletions quite well.</li>
                    <li>The separate chaining is considered the most efficient when the memory area reserved for hashing cannot be planned in advance.</li>
                </ul>
            </details>
        </article>
        <article>
            <details>
                <summary>Load balancing (computing)</summary>
                <p>If the number of collisions (k) is known the worst case for the Chaining is O(k).</p>
                <div>
                    <h2>Hash Table Performance - BigO</h2>
                    <table>
                        <tr>
                            <td>-</td>
                            <td>Worst Case</td>
                            <td>Average Case</td>
                            <td>Best Case</td>
                        </tr>
                        <tr>
                            <td>Linear probing</td>
                            <td>O(n)</td>
                            <td>O(1)</td>
                            <td>O(1)</td>
                        </tr>
                        <tr>
                            <td>Chaining</td>
                            <td>O(n)</td>
                            <td>O(1)</td>
                            <td>O(1)</td>
                        </tr>
                        <tr>
                            <td>Double-Hashing</td>
                            <td>O(n)</td>
                            <td>O(1)</td>
                            <td>O(1)</td>
                        </tr>
                    </table>
                </div>
                <div>
                    <h2>Load Balancing</h2>
                    <p>If too many elements were hashed into the same key: looking inside this key may take O(n) time.</p>
                    <p>Once a hash table has passed its load balance - it has to rehash (create a new bigger table, and re-insert each element to the table).</p>
                    <p>In computing, load balancing refers to the process of distributing a set of activities over a set of resources (computing units), with the aim of making their overall processing more efficient.</p>
                    <p>Load balancing can optimize response time and avoid unevenly overloading some compute nodes while other compute nodes remain idle.</p>
                    <img src="./images/load-balancing.gif" alt="">
                </div>
                <div>
                    <p>When open addressing is used as a collision resolution technique for a Hash Table implementation, N/M determines the load factor. N is the number of elements stored and M is the number of buckets available in the HashMap. 
                    </p> 
                    <p>
                    The HashMap should be rehashed every time a load factor of the implementation is about to be reached. This helps in maintaining a balanced HashMap which keeps the search operation efficiency close to O(1). Generally, a load factor of 0.75 is defined to keep the HashMap balanced.</p>
                </div>
                <!-- TODO add a table? -->
            </details>
        </article>
        <article>
            <details>
                <summary>Exercises</summary>
                <div>
                    <h2>Exercise 1</h2>
                    <p>The following hash function produces a hash collision every time there are two words that are anagrams (state, taste). Try to fix the hash function in order to not have a hash collision with two words that are anagrams.  </p>
                    <pre><code class="python">
hash = lambda x: sum(ord(char) for char in x) % 1000
print(hash("state")==hash("taste")) ### -> True
                    </code></pre>
                    <p>Here is a possible solution for avoiding the hash collision for words that are anagrams.</p>
                    <pre class="blur"><code class="python">
hash = lambda x: sum(ord(char) * i for i, char in enumerate(x)) % 1000
print(hash("state")==hash("taste")) ### -> False
                    </code></pre>
                </div>
                <div>
                <h2>Exercise 2</h2>
                <p>You have a list o words (vocabulary). Given a word, you have to find all other words in the vocabulary that are an anagram of the given word. 
                </p>
                <p>The time complexity for searching an anagram should be O(1)</p>
                <p>Example</p>
                <pre><code class="python">
vocabulary = ['study', 'bored', 'hint', 'car']

input = 'dusty'
output = 'study'

input = 'thin'
output = 'hint'

input = 'stuff'
output = False
                </code></pre>
                <p>Here is a possible solution for searching an anagram in a vocabulary with a time complexity O(1).</p>
                <pre class="blur"><code class="python">
vocabulary = ['study', 'bored', 'night', 'car', 'below']
hash = lambda x: sum(ord(char) for char in x) % 1000
hash_table = {hash(word): word for word in vocabulary}

# use case 1
hash('dusty') in hash_table and print(hash_table[hash('dusty')])  

# use case 3
hash('stuff') in hash_table and print(hash_table[hash('stuff')])  
                </code></pre>
                </div>

            </details>
        </article>
        <!-- 1573625332.pdf -->
        <!-- <article><details><summary>Practice Problems on Hashing</summary>
            <h2></h2>
            <ul>
                <li>What are the advantages and disadvantages of hash tables compared to binary search trees?</li>
            </ul>
        </details></article> -->
    </body>
    <script>
        hljs.highlightAll();
    </script>
</html>

<!-- http://www.btechsmartclass.com/data_structures/tree-terminology.html -->

