<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="UTF-8" />
        <meta http-equiv="X-UA-Compatible" content="IE=edge" />
        <meta name="viewport" content="width=device-width, initial-scale=1.0" />
        <title>Hash Table</title>
        <link rel="stylesheet" href="./main.css" />
        <link rel="stylesheet" href="./collapse.css" />
        <script src="vendors/highlight.min.js"></script>
        <script src="vendors/highlight.ln.min.js"></script>
        <link rel="stylesheet" href="vendors/highlight.min.css" />
    </head>
    <body>
        <!-- https://junminlee3.medium.com/hash-tables-animations-that-will-make-you-understand-how-they-work-d1bcc850ba71 -->
        <article id="introduction">
            <details>
                <summary>The Map Data Structure</summary>
                <h2>Why Hashing?</h2>
                <p>
                    Internet has grown to millions of users generating terabytes of content every day. According to internet data tracking services, the amount of content on the internet doubles every six months. With this kind of growth, it is impossible to find anything in the internet, unless we develop new data structures and algorithms for storing and accessing data. So what is wrong with traditional data structures like Arrays and Linked Lists? Suppose we have a very large data set stored in an array. The amount of time required to look up an element in the array is either O(log n) or O( n) based on whether the array is sorted or not. If the array is sorted then a technique such as binary search can be used to search the array. Otherwise, the array must be searched linearly. Either case may not be desirable if we need to process a very large data set. Therefore we discuss a new technique called hashing that allows us to update and retrieve any entry in constant time O(1). The constant time or O(1) performance means, the amount of time to perform the operation does not depend on data size n.
                </p>
                <h2>Definition</h2>
                <p>In a mathematical sense, a map is a relation between two sets. We can define Map M as a set of pairs, where each pair is of the form (key, value), where for given a key, we can find a value using some kind of a “function” that maps keys to values. The key for a given object can be calculated using a function called a hash function. In its simplest form, we can think of an array as a Map where key is the index and value is the value at that index. For example, given an array A, if i is the key, then we can find the value by simply looking up A[i]. The idea of a hash table is more generalized and can be described as follows.
                </p>
                <p>The concept of a hash table is a generalized idea of an array where key does not have to be an integer. We can have a name as a key, or for that matter any object as the key. The trick is to find a hash function to compute an index so that an object can be stored at a specific location in a table such that it can easily be found.</p>
                <var>hash: KEYS -> {0, 1, 2, ..., n - 1}</var>
                <img class="size-l" src="images/ht/brute-force.gif" alt="" />
                <h2>Example</h2>
                <p>Suppose we have a set of strings {“abc”, “def”, “ghi”} that we’d like to store in a table. Our objective here is to find or update them quickly from a table, actually in O(1). We are not concerned about ordering them or maintaining any order at all. Let us think of a simple schema to do this. Suppose we assign “a” = 1, “b”=2, ... etc to all alphabetical characters. We can then simply compute a number for each of the strings by using the sum of the characters as follows.</p>
                <var>“abc”=1+2+3=6, “def”=4+5+6=15 , “ghi”=7+8+9=24</var>
                <p>If we assume that we have a table of size 5 to store these strings, we can compute the
                    location of the string by taking the sum mod 5. So we will then store “abc” in 6 mod 5 = 1,“def” in 15 mod 5 = 0, and “ghi” in 24 mod 5 = 4 in locations 1, 0 and 4 as follows.</p>
                <pre><code class="python">
                    ["def", "abc", Null, Null, "ghi", Null]
                </code></pre>
                <h2>HAsh Function Definition</h2>
                <p>
                    A hash function over a set 𝑋 is a function 𝐻 that takes an element 𝑥 in 𝑋 and associates to 𝑥 an
                    integer 𝐻 (𝑥 ) in the interval [0, 𝑀 ), for some integer 𝑀 . In symbols
                    <pre>
                        𝐻 ∶𝑋 → [0,𝑀)
                    </pre>
                </p>
                <img class="size-l" src="./images/ht/hash-function.gif" alt="" />
                <img class="size-l" src="./images/ht/hash-function-module.gif" alt="" />
            </details>
        </article>
        <article>
            <details>
                <summary>Problem with Hashing</summary>
                <h2>Introduction</h2>
                <p>

                    The method discussed above seems too good to be true as we begin to think more about the hash function. 
                    First of all, the hash function we used, that is the sum of the letters, is a bad one. In case we have permutations of the same letters, “abc”, “bac” etc in the set, we will end up with the same value for the sum and hence the key. In this case, the strings would hash into the same location, creating what we call a “collision”. This is obviously not a good thing. Secondly, we need to find a good table size, preferably a prime number so that even if the sums are different, then collisions can be avoided, when we take mod of the sum to find the location. So we ask two questions.
                </p>
                <ul>
                    <li>Question 1: How do we pick a good hash function?</li>
                    <li>Question 2: How do we deal with collisions?</li>
                </ul>

                <div>
                    <h2>Hash Collission</h2>
                    <p></p>
                    <img class="size-l" src="./images/ht/hash-function-collision.gif" alt="" />
                </div>
                <div>
                    <h2>Hashing with Open Addressing</h2>
                    <p>The open addressing is a technique for collision resolution.</p>
                    <p>We can define open addressing in a general way as a hash table algorithm where the data always stay within the same vector. </p>
                    <p>
                        It inserts the data into the hash table itself. The size of the hash table should be larger than
                        the number of keys.
                    </p>
                    <img class="size-l" src="./images/ht/hash-open.addressing.gif" alt="" />
                </div>
                <div>
                    <h2>Hashing with Separate Chaining</h2>
                    <p>The open addressing is a technique for collision resolution.</p>
                    <p>
                        It inserts the data into the hash table itself. The size of the hash table should be larger than
                        the number of keys.
                    </p>
                    <img class="size-l" src="./images/ht/hash.separate-chaining.gif" alt="" />
                </div>
            </details>
        </article>
    </body>
    <script>
        hljs.highlightAll();
    </script>
</html>

<!-- http://www.btechsmartclass.com/data_structures/tree-terminology.html -->

